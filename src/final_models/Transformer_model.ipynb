{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89f63e37",
   "metadata": {},
   "source": [
    "# Transformer Model for Electricity Demand Forecasting\n",
    "\n",
    "This script implements a PyTorch Transformer model for time series forecasting of electricity demand.\n",
    "The model uses attention mechanisms to capture temporal dependencies in the data.\n",
    "\n",
    "## HOW TO RUN THIS FILE:\n",
    "\n",
    "1. **Prerequisites**: Ensure the processed dataset `complete_data.csv` is available in `../../data/processed/`\n",
    "2. **Run All Cells**: Execute cells sequentially from top to bottom using \"Run All\" or run each cell individually\n",
    "3. **Dependencies**: All required packages will be automatically installed in the initial section of the python script\n",
    "4. **Outputs**: The script generates performance metrics, feature importance analysis, and visualisation plots\n",
    "5. **Results**: Final model performance and predictions are saved in variables accessible throughout the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4d64cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.8.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "  Downloading torch-2.8.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/nwadmin/ZZSC9020-Group_F/.venv/lib/python3.10/site-packages (from torch) (4.15.0)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/nwadmin/ZZSC9020-Group_F/.venv/lib/python3.10/site-packages (from torch) (4.15.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch)\n",
      "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch)\n",
      "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.3 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.3 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch)\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch)\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.4.0 (from torch)\n",
      "  Downloading triton-3.4.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/nwadmin/ZZSC9020-Group_F/.venv/lib/python3.10/site-packages (from triton==3.4.0->torch) (80.9.0)\n",
      "Collecting triton==3.4.0 (from torch)\n",
      "  Downloading triton-3.4.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/nwadmin/ZZSC9020-Group_F/.venv/lib/python3.10/site-packages (from triton==3.4.0->torch) (80.9.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/nwadmin/ZZSC9020-Group_F/.venv/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.8.0-cp310-cp310-manylinux_2_28_x86_64.whl (888.0 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/888.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mRequirement already satisfied: MarkupSafe>=2.0 in /home/nwadmin/ZZSC9020-Group_F/.venv/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.8.0-cp310-cp310-manylinux_2_28_x86_64.whl (888.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m888.0/888.0 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m  \u001b[33m0:00:39\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m888.0/888.0 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m  \u001b[33m0:00:39\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m  \u001b[33m0:00:23\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m  \u001b[33m0:00:23\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m  \u001b[33m0:00:23\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m  \u001b[33m0:00:23\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/193.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m  \u001b[33m0:00:08\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m  \u001b[33m0:00:08\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m  \u001b[33m0:00:10\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m  \u001b[33m0:00:10\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m288.1/288.2 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m00:01\u001b[0m^C\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m288.1/288.2 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m^C\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m288.1/288.2 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dface2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import shap\n",
    "from sklearn.metrics import r2_score\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "#global variables\n",
    "patience = 20\n",
    "num_epochs = 100\n",
    "one_hot_features = ['is_summer', 'is_autumn', 'is_winter', 'is_spring',\n",
    "                    'is_monday', 'is_tuesday', 'is_wednesday', 'is_thursday', 'is_friday', 'is_saturday', 'is_sunday',\n",
    "                    'is_weekday', 'is_weekend',\n",
    "                    'is_jan', 'is_feb', 'is_mar', 'is_apr', 'is_may', 'is_jun', 'is_jul', 'is_aug', 'is_sep', 'is_oct', 'is_nov', 'is_dec'\n",
    "                    ]\n",
    "\n",
    "#load and prepare data\n",
    "def prepare_data(params):\n",
    "    # 1. Load data\n",
    "    # Get the repository root directory (two levels up from this file)\n",
    "    current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    repo_root = os.path.dirname(os.path.dirname(current_dir))\n",
    "    DATA_DIR = os.path.join(repo_root, 'data')\n",
    "\n",
    "    if params[\"dataset\"] == \"2016-2019\":\n",
    "        data = pd.read_csv(os.path.join(DATA_DIR, 'processed/processed2.csv'))\n",
    "        datetimes = pd.to_datetime(data['datetime_au'])\n",
    "    elif params[\"dataset\"] == \"2010-2019\":\n",
    "        data = pd.read_csv(os.path.join(DATA_DIR, 'processed/processed_full.csv'))\n",
    "        datetimes = pd.to_datetime(data['datetime_au'], dayfirst=True)\n",
    "\n",
    "    # Select desired features\n",
    "    data = data[params['features']]\n",
    "\n",
    "    # Separate one-hot and continuous features\n",
    "    continuous_features = [f for f in params['features'] if f not in one_hot_features]\n",
    "    one_hot_feats = [f for f in params['features'] if f in one_hot_features]\n",
    "\n",
    "    # Scale only continuous features\n",
    "    scaler = StandardScaler()\n",
    "    scaled_continuous = scaler.fit_transform(data[continuous_features].values)\n",
    "    scaled_continuous = torch.FloatTensor(scaled_continuous)\n",
    "\n",
    "    # Get one-hot features as tensor\n",
    "    one_hot_tensor = torch.FloatTensor(data[one_hot_feats].values)\n",
    "\n",
    "    # Concatenate scaled continuous and one-hot features\n",
    "    scaled_data = torch.cat([scaled_continuous, one_hot_tensor], dim=1)\n",
    "\n",
    "    # 3. Create sequences and targets\n",
    "    sequences = []\n",
    "    targets = []\n",
    "\n",
    "    for i in range(len(scaled_data) - params[\"seq_length\"]):\n",
    "        sequences.append(scaled_data[i:i+params[\"seq_length\"]])  # sequence of 7 days\n",
    "        targets.append(scaled_data[i+params[\"seq_length\"], 0])   # predict next day's demand (column 0)\n",
    "\n",
    "    sequences = torch.stack(sequences)\n",
    "    targets = torch.FloatTensor(targets).unsqueeze(1)  # shape: (n, 1)\n",
    "\n",
    "    return sequences, targets, datetimes, scaler\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    \"\"\"Create sequences of length seq_length from the data\"\"\"\n",
    "    sequences = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        seq = data[i:i+seq_length]\n",
    "        sequences.append(seq)\n",
    "    return torch.stack(sequences)\n",
    "\n",
    "def create_targets(data, seq_length):\n",
    "    \"\"\"Create targets for each sequence (the next demand value after the sequence)\"\"\"\n",
    "    targets = []\n",
    "    for i in range(seq_length, len(data)):\n",
    "        target = data[i, 0]  # Assuming demand is the first feature\n",
    "        targets.append(target)\n",
    "    return torch.stack(targets)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0) # Shape: (1, max_len, d_model)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        return x\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, d_model, nhead, num_layers, dim_feedforward, dropout=0.1, activation='relu'):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.input_projection = nn.Linear(input_dim, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            activation=activation,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.output_layer = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n",
    "        src_projected = self.input_projection(src) * math.sqrt(self.d_model)\n",
    "        src_projected = self.pos_encoder(src_projected)\n",
    "        encoder_output = self.transformer_encoder(src_projected, mask=src_mask, src_key_padding_mask=src_key_padding_mask)\n",
    "        last_time_step_output = encoder_output[:, -1, :]\n",
    "        output = self.output_layer(last_time_step_output)\n",
    "        return output\n",
    "\n",
    "def train_transformer_model(sequences, targets, input_dim, datetimes, params):\n",
    "    \"\"\"Train the Transformer model\"\"\"\n",
    "    datetimes = pd.to_datetime(datetimes)\n",
    "\n",
    "    if params[\"train_test_split\"] == \"80:20\":\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "        sequences, targets, test_size=0.2, shuffle=False\n",
    "        )\n",
    "    elif params[\"train_test_split\"] == \"prior:2019\":\n",
    "        train_mask = datetimes.dt.year != 2019\n",
    "        test_mask  = datetimes.dt.year == 2019\n",
    "        seq_train_mask = train_mask[params['seq_length']:].to_numpy()\n",
    "        seq_test_mask  = test_mask[params['seq_length']:].to_numpy()\n",
    "        X_train, y_train = sequences[seq_train_mask], targets[seq_train_mask]\n",
    "        X_val,   y_val   = sequences[seq_test_mask], targets[seq_test_mask]\n",
    "    \n",
    "    X_train_tensor = torch.FloatTensor(X_train)\n",
    "    X_val_tensor   = torch.FloatTensor(X_val)\n",
    "    y_train_tensor = torch.FloatTensor(y_train)\n",
    "    y_val_tensor   = torch.FloatTensor(y_val)\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    val_dataset   = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=params['batch_size'], shuffle=True)\n",
    "    val_loader   = DataLoader(val_dataset, batch_size=params['batch_size'], shuffle=False)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model = TransformerModel(\n",
    "        input_dim=input_dim,\n",
    "        d_model=params[\"transformer_encoder_layer_params\"]['d_model'],\n",
    "        nhead=params[\"transformer_encoder_layer_params\"]['nhead'],\n",
    "        num_layers=params[\"transformer_layer_params\"]['num_layers'],\n",
    "        dim_feedforward=params[\"transformer_encoder_layer_params\"]['dim_feedforward'],\n",
    "        dropout=params[\"transformer_encoder_layer_params\"]['dropout'],\n",
    "        activation=params[\"transformer_encoder_layer_params\"]['activation']\n",
    "    ).to(device)\n",
    "\n",
    "    # These are pretty standard choices\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params[\"learning_rate\"], weight_decay=1e-5)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(batch_X)\n",
    "            loss = criterion(predictions, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * batch_X.size(0)\n",
    "        \n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in val_loader:\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                predictions = model(batch_X)\n",
    "                loss = criterion(predictions, batch_y)\n",
    "                val_loss += loss.item() * batch_X.size(0)\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "        \n",
    "        if epochs_no_improve >= patience:\n",
    "            break\n",
    "\n",
    "    # Return train/test splits for postprocess\n",
    "    return model, train_losses, val_losses, X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor\n",
    "\n",
    "def evaluate_model(model, X_val, y_val, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_val_tensor = torch.FloatTensor(X_val).to(device)\n",
    "        predictions = model(X_val_tensor)\n",
    "        predictions = predictions.cpu().numpy()\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def postprocess(model, X_train, y_train, X_test, y_test, scaler, train_losses, val_losses, params, visualise=False):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Get continuous feature count\n",
    "    continuous_features = [f for f in range(len(params['features'])) if f not in [params['features'].index(f) for f in one_hot_features if f in params['features']]]\n",
    "    n_cont = len(continuous_features)\n",
    "\n",
    "    # Train set\n",
    "    train_predictions = evaluate_model(model, X_train.numpy(), y_train.numpy(), device)\n",
    "    dummy_train = np.zeros((len(train_predictions), n_cont))\n",
    "    dummy_train[:, 0] = train_predictions.flatten()\n",
    "    train_predictions_original = scaler.inverse_transform(dummy_train)[:, 0]\n",
    "    dummy_train[:, 0] = y_train.numpy().flatten()\n",
    "    train_targets_original = scaler.inverse_transform(dummy_train)[:, 0]\n",
    "    train_mse = np.mean((train_predictions_original - train_targets_original) ** 2)\n",
    "    train_mae = np.mean(np.abs(train_predictions_original - train_targets_original))\n",
    "    train_rmse = np.sqrt(train_mse)\n",
    "    train_mape = np.mean(np.abs((train_predictions_original - train_targets_original) / train_targets_original)) * 100\n",
    "\n",
    "    # Test set\n",
    "    test_predictions = evaluate_model(model, X_test.numpy(), y_test.numpy(), device)\n",
    "    dummy_test = np.zeros((len(test_predictions), n_cont))\n",
    "    dummy_test[:, 0] = test_predictions.flatten()\n",
    "    test_predictions_original = scaler.inverse_transform(dummy_test)[:, 0]\n",
    "    dummy_test[:, 0] = y_test.numpy().flatten()\n",
    "    test_targets_original = scaler.inverse_transform(dummy_test)[:, 0]\n",
    "    test_mse = np.mean((test_predictions_original - test_targets_original) ** 2)\n",
    "    test_mae = np.mean(np.abs(test_predictions_original - test_targets_original))\n",
    "    test_rmse = np.sqrt(test_mse)\n",
    "    test_mape = np.mean(np.abs((test_predictions_original - test_targets_original) / test_targets_original)) * 100\n",
    "\n",
    "\n",
    "    results = {\n",
    "        'train_mse': train_mse,\n",
    "        'train_mae': train_mae,\n",
    "        'train_rmse': train_rmse,\n",
    "        'train_mape': train_mape,\n",
    "        'test_mse': test_mse,\n",
    "        'test_mae': test_mae,\n",
    "        'test_rmse': test_rmse,\n",
    "        'test_mape': test_mape,\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'test_targets_original': test_targets_original,\n",
    "        'test_predictions_original': test_predictions_original\n",
    "    }\n",
    "    return results\n",
    "\n",
    "def train_model(params):\n",
    "    input_dim = len(params['features'])\n",
    "    sequences, targets, datetimes, scaler_X = prepare_data(params)\n",
    "    # Get train/test splits from train_transformer_model\n",
    "    model, train_losses, val_losses, X_train, y_train, X_test, y_test = train_transformer_model(\n",
    "        sequences, targets, input_dim, datetimes, params\n",
    "    )\n",
    "    results = postprocess(model, X_train, y_train, X_test, y_test, scaler_X, train_losses, val_losses, params, params['visualise'])\n",
    "    return results, model, X_train, y_train, X_test, y_test\n",
    "\n",
    "def median_model(params, runs):\n",
    "    # Calculate median MAPE over 'runs' runs, saving all model parameters for each run\n",
    "    models_list = []\n",
    "    # Run 'runs' times, save all results\n",
    "    for i in range(runs):\n",
    "        results, model, X_train, y_train, X_test, y_test = train_model(params)\n",
    "        models_list.append({\n",
    "            'results': results,\n",
    "            'model': model,\n",
    "            'X_train': X_train,\n",
    "            'y_train': y_train,\n",
    "            'X_test': X_test,\n",
    "            'y_test': y_test,\n",
    "        })\n",
    "    # Find the median MAPE index\n",
    "    # Find the median MAPE index robustly (works for even or odd runs)\n",
    "    test_mapes = [entry['results']['test_mape'] for entry in models_list]\n",
    "    median_mape = np.median(test_mapes)\n",
    "    # Find the index of the model whose test_mape is closest to the median\n",
    "    median_idx = np.argmin(np.abs(np.array(test_mapes) - median_mape))\n",
    "    median_entry = models_list[median_idx]\n",
    "    # Visualise only the best (median) model\n",
    "    if params['visualise']:\n",
    "        visualise_model_results(median_entry['results'], runs)\n",
    "    return median_entry\n",
    "\n",
    "def visualise_model_results(results, runs):\n",
    "    print(f\"Median Model Results after {runs} runs:\")\n",
    "    print(f\"\\nTrain Set Metrics:\")\n",
    "    print(f\"MSE: {results['train_mse']:.4f}\")\n",
    "    print(f\"MAE: {results['train_mae']:.4f}\")\n",
    "    print(f\"RMSE: {results['train_rmse']:.4f}\")\n",
    "    print(f\"MAPE: {results['train_mape']:.4f}\")\n",
    "\n",
    "    print(f\"\\nTest Set Metrics:\")\n",
    "    print(f\"MSE: {results['test_mse']:.4f}\")\n",
    "    print(f\"MAE: {results['test_mae']:.4f}\")\n",
    "    print(f\"RMSE: {results['test_rmse']:.4f}\")\n",
    "    print(f\"MAPE: {results['test_mape']:.4f}\")\n",
    "\n",
    "    # Plot results (test set)\n",
    "    plot_results(results['train_losses'], results['val_losses'], results['test_targets_original'], results['test_predictions_original'])\n",
    "\n",
    "def plot_results(train_losses, val_losses, y_val, predictions):\n",
    "    fig = plt.figure(figsize=(22, 7))\n",
    "    gs = GridSpec(1, 3, width_ratios=[1, 1, 2])  # 25%, 25%, 50%\n",
    "\n",
    "    # 1. Predicted vs Actual (Scatter)\n",
    "    ax0 = fig.add_subplot(gs[0])\n",
    "    ax0.scatter(y_val, predictions, color='blue', alpha=0.7, s=20)\n",
    "    ax0.plot([min(y_val), max(y_val)], [min(y_val), max(y_val)], 'r--', label='Perfect Prediction')\n",
    "    r2 = r2_score(y_val, predictions)\n",
    "    ax0.text(0.05, 0.95, f'$R^2$ = {r2:.4f}', transform=ax0.transAxes, fontsize=13, verticalalignment='top', bbox=dict(boxstyle=\"round\", fc=\"w\"))\n",
    "    ax0.set_xlabel('Actual Values')\n",
    "    ax0.set_ylabel('Predicted Values')\n",
    "    ax0.set_title('Predicted vs Actual (Test Data)')\n",
    "    ax0.legend()\n",
    "    ax0.grid(True)\n",
    "\n",
    "    # 2. Residuals Plot\n",
    "    ax1 = fig.add_subplot(gs[1])\n",
    "    residuals = predictions - y_val\n",
    "    ax1.scatter(predictions, residuals, color='green', alpha=0.7, s=20)\n",
    "    ax1.axhline(0, color='red', linestyle='--')\n",
    "    ax1.set_xlabel('Predicted Values')\n",
    "    ax1.set_ylabel('Residuals')\n",
    "    ax1.set_title('Residuals Plot')\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # 3. Time Series Comparison (first 365 points)\n",
    "    ax2 = fig.add_subplot(gs[2])\n",
    "    ax2.plot(y_val[-365:], label='Actual', color='blue')\n",
    "    ax2.plot(predictions[-365:], label='Predicted', color='red')\n",
    "    ax2.set_xlabel('Time Index')\n",
    "    ax2.set_ylabel('Demand Values')\n",
    "    ax2.set_title('Time Series Comparison (365 points)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_results.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def explain_transformer_feature_importance(model, X_train, X_test, params):\n",
    "    # Flatten sequences for SHAP\n",
    "    X_train_flat = X_train.numpy().reshape(X_train.shape[0], -1)\n",
    "    X_test_flat  = X_test.numpy().reshape(X_test.shape[0], -1)\n",
    "\n",
    "    # Prediction function for SHAP\n",
    "    def predict_fn(x):\n",
    "        x_torch = torch.FloatTensor(x).reshape(-1, params['seq_length'], len(params['features']))\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = model(x_torch.to(device)).cpu().numpy()\n",
    "        return preds\n",
    "\n",
    "    # Select background and samples to explain\n",
    "    background = X_train_flat[:500]\n",
    "    X_explain  = X_test_flat\n",
    "\n",
    "    # SHAP KernelExplainer\n",
    "    explainer = shap.KernelExplainer(predict_fn, background)\n",
    "    shap_values = explainer.shap_values(X_explain, nsamples=100)\n",
    "\n",
    "    # Reshape SHAP values to (samples, seq_length, features)\n",
    "    shap_values_reshaped = np.array(shap_values).reshape(X_explain.shape[0], params['seq_length'], len(params['features']))\n",
    "\n",
    "    # Aggregate importance across samples and timesteps\n",
    "    feature_importance = np.mean(np.abs(shap_values_reshaped), axis=(0, 1))\n",
    "\n",
    "    # Plot\n",
    "    feature_names = params['features']\n",
    "    sorted_idx = np.argsort(feature_importance)[::-1]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(np.array(feature_names)[sorted_idx], feature_importance[sorted_idx])\n",
    "    plt.xlabel(\"Mean |SHAP value|\")\n",
    "    plt.title(\"Feature Importance (Transformer)\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
